{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c975e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import wandb.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3e3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    data = 'CaseStudy_training_data.xlsx'\n",
    "    df = pd.read_excel(data, sheet_name='Model_data')\n",
    "    \n",
    "    # Handle missing values and duplicates\n",
    "    df_cleaned = df.dropna()\n",
    "    df_cleaned = df_cleaned.drop_duplicates()\n",
    "    df_cleaned = df_cleaned.drop(['ID'], axis=1)\n",
    "    df_cleaned = df_cleaned.rename(columns={'rx ds': 'rx_ds'})\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df_features = df_cleaned.copy()\n",
    "    df_features['rx_ds_bucket'] = pd.qcut(df_cleaned['rx_ds'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    \n",
    "    binary_cols = [col for col in df_features.columns if col not in ['OD', 'rx_ds', 'rx_ds_bucket']]\n",
    "    df_features['binary_sum'] = df_features[binary_cols].sum(axis=1)\n",
    "    df_features['rx_ds_to_binary_sum'] = df_features['rx_ds'] / df_features['binary_sum']\n",
    "    \n",
    "    # One-Hot Encoding\n",
    "    df_one_hot = pd.get_dummies(df_features['rx_ds_bucket'], prefix='rx_ds_bucket')\n",
    "    df_features = pd.concat([df_features, df_one_hot], axis=1)\n",
    "    df_features.drop(['rx_ds_bucket'], axis=1, inplace=True)\n",
    "    \n",
    "    # Splitting the data\n",
    "    X = df_features.drop('OD', axis=1)\n",
    "    y = df_features['OD']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, X_test, hyperparameters):\n",
    "    model = LogisticRegression(**hyperparameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return model, y_pred\n",
    "\n",
    "def calculate_performance_metrics(y_test, y_pred, model, X_test):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "    metrics[\"precision\"] = precision_score(y_test, y_pred)\n",
    "    metrics[\"recall\"] = recall_score(y_test, y_pred)\n",
    "    metrics[\"f1\"] = f1_score(y_test, y_pred)\n",
    "    metrics[\"roc_auc\"] = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    \n",
    "    metrics[\"ppv\"] = TP / (TP + FP)\n",
    "    metrics[\"npv\"] = TN / (TN + FN)\n",
    "    metrics[\"specificity\"] = TN / (TN + FP)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def log_to_wandb(metrics, model, X_train, X_test, y_train, y_test):\n",
    "    # Log metrics\n",
    "    wandb.log(metrics)\n",
    "    \n",
    "    # Save and log the model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    model_path = \"models/log_model.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    artifact = wandb.Artifact(\"log_model\", type=\"model\")\n",
    "    artifact.add_file(model_path)\n",
    "    wandb.log_artifact(artifact)\n",
    "    \n",
    "    # Save and log the data\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    datasets = {\"training_data\": X_train, \"training_labels\": y_train, \"test_data\": X_test, \"test_labels\": y_test}\n",
    "    \n",
    "    for name, df in datasets.items():\n",
    "        df.to_csv(f'data/{name}.csv', index=False)\n",
    "    \n",
    "    artifact = wandb.Artifact('train_val_sets', type='dataset', metadata={\"Source\": \"CaseStudy_training_data.xlsx\"})\n",
    "    artifact.add_dir('data')\n",
    "    wandb.log_artifact(artifact)\n",
    "    \n",
    "    # Plot plots to Weights & Biases\n",
    "    label_names = [\"Not-OD\", \"OD\"]\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    wandb.sklearn.plot_class_proportions(y_train, y_test, label_names)\n",
    "    wandb.sklearn.plot_summary_metrics(model, X_train, y_train, X_test, y_test)\n",
    "    wandb.sklearn.plot_roc(y_test, y_pred_proba, labels=label_names)\n",
    "    wandb.sklearn.plot_precision_recall(y_test, y_pred_proba, labels=label_names)\n",
    "    wandb.sklearn.plot_confusion_matrix(y_test, y_pred_proba.argmax(axis=1), labels=label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3363b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search Hyperparameters\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "      'name': 'recall', # \n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'C': {\n",
    "            'values': [0.1, 1, 10]\n",
    "        },\n",
    "        'max_iter': {\n",
    "            'values': [100, 200, 300]\n",
    "        },\n",
    "        'penalty': {\n",
    "            'values': ['l1', 'l2']\n",
    "        },\n",
    "        'solver': {\n",
    "            'values': ['liblinear', 'saga']\n",
    "        },\n",
    "        'class_weight': {\n",
    "            'values': ['balanced', None]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e4e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Hyperparameters\n",
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'metric': {\n",
    "      'name': 'recall',\n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'C': {\n",
    "            'values': [0.1, 1, 10]\n",
    "        },\n",
    "        'max_iter': {\n",
    "            'values': [100, 200, 300]\n",
    "        },\n",
    "        'penalty': {\n",
    "            'values': ['l1', 'l2']\n",
    "        },\n",
    "        'solver': {\n",
    "            'values': ['liblinear', 'saga']\n",
    "        },\n",
    "        'class_weight': {\n",
    "            'values': ['balanced', None]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8da631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Search Hyperparameters\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "      'name': 'recall',\n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'C': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.1,\n",
    "            'max': 10\n",
    "        },\n",
    "        'max_iter': {\n",
    "            'distribution': 'int_uniform',\n",
    "            'min': 100,\n",
    "            'max': 300\n",
    "        },\n",
    "        'penalty': {\n",
    "            'values': ['l1', 'l2']\n",
    "        },\n",
    "        'solver': {\n",
    "            'values': ['liblinear', 'saga']\n",
    "        },\n",
    "        'class_weight': {\n",
    "            'values': ['balanced', None]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd6ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep():\n",
    "    # Initialize wandb\n",
    "    run = wandb.init()\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Get hyperparameters from wandb\n",
    "    hyperparameters = run.config\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    model, y_pred = train_logistic_regression(X_train, y_train, X_test, hyperparameters)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    metrics = calculate_performance_metrics(y_test, y_pred, model, X_test)\n",
    "    \n",
    "    # Log to wandb\n",
    "    log_to_wandb(metrics, model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Finish the wandb run\n",
    "    run.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8084d787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: aao41419\n",
      "Sweep URL: https://wandb.ai/dev_ml_ops/wandb-sweep/sweeps/aao41419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bxfijlij with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tC: 5.56533472706193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weight: balanced\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_iter: 225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpenalty: l1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsolver: saga\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/wandb_demo/wandb/run-20231031_181333-bxfijlij</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dev_ml_ops/wandb-sweep/runs/bxfijlij' target=\"_blank\">hopeful-sweep-1</a></strong> to <a href='https://wandb.ai/dev_ml_ops/wandb-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dev_ml_ops/wandb-sweep/sweeps/aao41419' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sweep/sweeps/aao41419</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dev_ml_ops/wandb-sweep' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dev_ml_ops/wandb-sweep/sweeps/aao41419' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sweep/sweeps/aao41419</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dev_ml_ops/wandb-sweep/runs/bxfijlij' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sweep/runs/bxfijlij</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/hc_opioid/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data)... Done. 0.0s\n",
      "/opt/conda/envs/hc_opioid/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>f1</td><td>▁</td></tr><tr><td>npv</td><td>▁</td></tr><tr><td>ppv</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr><tr><td>specificity</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.525</td></tr><tr><td>f1</td><td>0.44444</td></tr><tr><td>npv</td><td>0.76136</td></tr><tr><td>ppv</td><td>0.33929</td></tr><tr><td>precision</td><td>0.33929</td></tr><tr><td>recall</td><td>0.64407</td></tr><tr><td>roc_auc</td><td>0.59959</td></tr><tr><td>specificity</td><td>0.47518</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-sweep-1</strong> at: <a href='https://wandb.ai/dev_ml_ops/wandb-sweep/runs/bxfijlij' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sweep/runs/bxfijlij</a><br/>Synced 6 W&B file(s), 5 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231031_181333-bxfijlij/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = '03_wandb_log_sweep.ipynb' # Failed to detect the name of this notebook...\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project='wandb-sweep')\n",
    "wandb.agent(sweep_id, function=sweep, count=1)  # Adjust 'count' as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a865b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hc_opioid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
