{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base on wandb documentation: Scikit-learn integration\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import pickle\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, roc_curve, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed to detect the name of this notebook...\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '04_opiod_wandb_tree.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33midiazl\u001b[0m (\u001b[33mdev_ml_ops\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'CaseStudy_training_data.xlsx'\n",
    "df = pd.read_excel(data, sheet_name='Model_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "df_cleaned = df_cleaned.drop(['ID'], axis=1)\n",
    "df_cleaned = df_cleaned.rename(columns={'rx ds': 'rx_ds'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform percentile-based bucketing for 'rx_ds'\n",
    "df_features = df_cleaned.copy()\n",
    "df_features['rx_ds_bucket'] = pd.qcut(\n",
    "    df_cleaned['rx_ds'], \n",
    "    q=4, \n",
    "    labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature that is the sum of all the binary features\n",
    "binary_cols = [col for col in df_features.columns if col not in ['OD', 'rx_ds', 'rx_ds_bucket']]\n",
    "df_features['binary_sum'] = df_features[binary_cols].sum(axis=1)\n",
    "\n",
    "# Create a new feature that is the ratio of 'rx_ds' to the sum of binary features\n",
    "df_features['rx_ds_to_binary_sum'] = df_features['rx_ds'] / df_features['binary_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for 'rx_ds_bucket'\n",
    "df_one_hot = pd.get_dummies(df_features['rx_ds_bucket'], prefix='rx_ds_bucket')\n",
    "df_features = pd.concat([df_features, df_one_hot], axis=1)\n",
    "df_features.drop(['rx_ds_bucket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_tree = df_features.copy()\n",
    "\n",
    "X = df_tree.drop(['OD', 'rx_ds'], axis=1)\n",
    "y = df_tree['OD']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to calculate the metrics for the classifier\n",
    "def calculate_metrics(y_test, y_pred, model, X_test):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "    metrics[\"precision\"] = precision_score(y_test, y_pred)\n",
    "    metrics[\"recall\"] = recall_score(y_test, y_pred)\n",
    "    metrics[\"f1\"] = f1_score(y_test, y_pred)\n",
    "    metrics[\"roc_auc\"] = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    \n",
    "    metrics[\"ppv\"] = TP / (TP + FP)\n",
    "    metrics[\"npv\"] = TN / (TN + FN)\n",
    "    metrics[\"specificity\"] = TN / (TN + FP)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate tthe metrics speciffically for the tree model\n",
    "def calculate_tree_metrics(model, X_test, y_test):\n",
    "    tree_metrics = {}\n",
    "    tree_metrics[\"tree_depth\"] = model.get_depth()\n",
    "    tree_metrics[\"num_leaves\"] = model.get_n_leaves()\n",
    "    ccp_path = model.cost_complexity_pruning_path(X_test, y_test)\n",
    "    tree_metrics[\"ccp_alphas\"] = ccp_path.ccp_alphas\n",
    "    tree_metrics[\"impurities\"] = ccp_path.impurities\n",
    "    \n",
    "    return tree_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New wandb project and run\n",
    "run = wandb.init(project='wandb-sklearn-tree', name=\"classifier_decision_tree\")\n",
    "\n",
    "tree_params = {\n",
    "    'criterion': 'gini',\n",
    "    'splitter': 'best',\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "wandb.config = tree_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model, Fitting and predicting\n",
    "tree_model = DecisionTreeClassifier(**wandb.config)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree to nderstand the decision paths and criteria at each node\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_model, filled=True, rounded=True, class_names=[\"Not OD\", \"OD\"], feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Feature Importances\n",
    "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': tree_model.feature_importances_})\n",
    "feature_importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree characteristics and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How complex the model is. A deeper tree might have a higher chance of overfitting\n",
    "tree_depth = tree_model.get_depth()\n",
    "tree_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another measure for model complexity\n",
    "num_leaves = tree_model.get_n_leaves()\n",
    "num_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the decision paths for specific samples\n",
    "decision_paths = tree_model.decision_path(X_test)\n",
    "decision_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning to improve performance, and avoiding overfitting\n",
    "ccp_path = tree_model.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging the performance metrics\n",
    "y_pred = tree_model.predict(X_test)\n",
    "tree_metrics = calculate_metrics(y_test, y_pred, tree_model, X_test)\n",
    "\n",
    "wandb.log(tree_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging the tree characteristics\n",
    "tree_characteristics = calculate_tree_metrics(tree_model, X_test, y_test)\n",
    "\n",
    "wandb.log(tree_characteristics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact log_mode>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "with open(\"models/tree_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tree_model, f)\n",
    "\n",
    "# Log the model as a versioned file\n",
    "artifact = wandb.Artifact(\"tree_model\", type=\"model\")\n",
    "artifact.add_file(\"models/tree_model.pkl\")\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact train_val_sets>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the data\n",
    "os.makedirs('data', exist_ok=True)\n",
    "datasets = {\"trainig\": X, \"validation\": y}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    df.to_csv(f'data/{name}.csv', index=False)\n",
    "\n",
    "# Log the `data` as an artifact\n",
    "artifact = wandb.Artifact('train_val_sets', type='dataset', metadata={\"Source\": \"CaseStudy_training_data.xlsx\"})\n",
    "artifact.add_dir('data')\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaef7dcad300495fb4422781158573ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>f1</td><td>▁</td></tr><tr><td>npv</td><td>▁</td></tr><tr><td>ppv</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr><tr><td>specificity</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.715</td></tr><tr><td>f1</td><td>0.6069</td></tr><tr><td>npv</td><td>0.86842</td></tr><tr><td>ppv</td><td>0.51163</td></tr><tr><td>precision</td><td>0.51163</td></tr><tr><td>recall</td><td>0.74576</td></tr><tr><td>roc_auc</td><td>0.78002</td></tr><tr><td>specificity</td><td>0.70213</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classifier_firday_nght</strong> at: <a href='https://wandb.ai/dev_ml_ops/wandb-sklearn/runs/8f4v9hv1' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sklearn/runs/8f4v9hv1</a><br/> View job at <a href='https://wandb.ai/dev_ml_ops/wandb-sklearn/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMDM4MTg5Mw==/version_details/v2' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sklearn/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMDM4MTg5Mw==/version_details/v2</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231027_170612-8f4v9hv1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
