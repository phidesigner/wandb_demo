{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base on wandb documentation: Scikit-learn integration\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import pickle\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, roc_curve, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent error: Failed to detect the name of this notebook...\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '06_opiod_wandb_tree.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33midiazl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'CaseStudy_training_data.xlsx'\n",
    "df = pd.read_excel(data, sheet_name='Model_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "df_cleaned = df_cleaned.drop(['ID'], axis=1)\n",
    "df_cleaned = df_cleaned.rename(columns={'rx ds': 'rx_ds'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform percentile-based bucketing for 'rx_ds'\n",
    "df_features = df_cleaned.copy()\n",
    "df_features['rx_ds_bucket'] = pd.qcut(\n",
    "    df_cleaned['rx_ds'], \n",
    "    q=4, \n",
    "    labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for 'rx_ds_bucket'\n",
    "df_one_hot = pd.get_dummies(df_features['rx_ds_bucket'], prefix='rx_ds_bucket')\n",
    "df_features = pd.concat([df_features, df_one_hot], axis=1)\n",
    "df_features.drop(['rx_ds_bucket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_tree = df_features.copy()\n",
    "\n",
    "X = df_tree.drop(['OD', 'rx_ds'], axis=1)\n",
    "y = df_tree['OD']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to calculate the metrics for the classifier\n",
    "def calculate_metrics(y_test, y_pred, model, X_test):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "    metrics[\"precision\"] = precision_score(y_test, y_pred)\n",
    "    metrics[\"recall\"] = recall_score(y_test, y_pred)\n",
    "    metrics[\"f1\"] = f1_score(y_test, y_pred)\n",
    "    metrics[\"roc_auc\"] = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    \n",
    "    metrics[\"ppv\"] = TP / (TP + FP)\n",
    "    metrics[\"npv\"] = TN / (TN + FN)\n",
    "    metrics[\"specificity\"] = TN / (TN + FP)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate tthe metrics speciffically for the tree model\n",
    "def calculate_tree_metrics(model, X_test, y_test):\n",
    "    tree_metrics = {}\n",
    "    tree_metrics[\"tree_depth\"] = model.get_depth()\n",
    "    tree_metrics[\"num_leaves\"] = model.get_n_leaves()\n",
    "    ccp_path = model.cost_complexity_pruning_path(X_test, y_test)\n",
    "    tree_metrics[\"ccp_alphas\"] = ccp_path.ccp_alphas\n",
    "    tree_metrics[\"impurities\"] = ccp_path.impurities\n",
    "    \n",
    "    return tree_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New wandb project and run\n",
    "run = wandb.init(project='wandb-sklearn-tree-test1',\n",
    "                 name=\"classifier_decision_tree-test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_hyperparams = {\n",
    "    'criterion': 'entropy', # Measure for the quality of a split.\n",
    "    'splitter': 'random', # best\n",
    "    'max_depth': 50, \n",
    "    'min_samples_split': 10, # Minimum number of samples required to split an internal node.\n",
    "    'min_samples_leaf': 4, # Minimum number of samples required to be at a leaf node.\n",
    "    'max_features': None, # Maximum number of features considered for splitting a node.\n",
    "    'max_leaf_nodes': 30, # Maximum number of leaf nodes in the tree.\n",
    "    'min_impurity_decrease': 0.0, # Minimum impurity decrease required for a split to occur.\n",
    "    'min_weight_fraction_leaf': 0.15, # Minimum weighted fraction of the sum total of weights required to be at a leaf node.\n",
    "    'class_weight': 'balanced', # Weights associated with classes in the form {class_label: weight}.\n",
    "    'ccp_alpha': 0.0, # Complexity parameter used for Minimal Cost-Complexity Pruning.\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "\n",
    "wandb.config = tree_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterantevely\n",
    "tree_hyperparams = {\n",
    "    'criterion': 'entropy',\n",
    "    'splitter': 'best',\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': None,\n",
    "    'max_leaf_nodes': 10,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'class_weight': 'balanced',\n",
    "    'ccp_alpha': 0.0,\n",
    "    'random_state': 42\n",
    "}\n",
    "wandb.config = tree_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model, Fitting and predicting\n",
    "tree_model = DecisionTreeClassifier(**wandb.config)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the metrics\n",
    "y_pred = tree_model.predict(X_test)\n",
    "classification_metrics = calculate_metrics(y_test, y_pred, tree_model, X_test)\n",
    "tree_metrics = calculate_tree_metrics(tree_model, X_test, y_test)\n",
    "\n",
    "# Classification Metrics DataFrame\n",
    "results_classification = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision (PPV)', 'Recall (Sensitivity)', 'Specificity', 'F1 Score', 'Positive Predictive Value (PPV)', 'Negative Predictive Value (NPV)', 'ROC AUC'],\n",
    "    'Value': [classification_metrics['accuracy'], classification_metrics['precision'], classification_metrics['recall'], classification_metrics['specificity'], classification_metrics['f1'], classification_metrics['ppv'], classification_metrics['npv'], classification_metrics['roc_auc']]\n",
    "})\n",
    "\n",
    "# Round numerical values to 2 decimal places\n",
    "results_classification['Value'] = results_classification['Value'].round(2)\n",
    "\n",
    "# Decision Tree Metrics DataFrame\n",
    "results_tree = pd.DataFrame({\n",
    "    'Metric': ['Tree Depth', 'Number of Leaves', 'CCP Alphas', 'Impurities'],\n",
    "    'Value': [tree_metrics['tree_depth'], tree_metrics['num_leaves'], tree_metrics['ccp_alphas'], tree_metrics['impurities']]\n",
    "})\n",
    "\n",
    "# Convert arrays to string for better representation\n",
    "results_tree.loc[results_tree['Metric'].isin(['CCP Alphas', 'Impurities']), 'Value'] = results_tree.loc[results_tree['Metric'].isin(['CCP Alphas', 'Impurities']), 'Value'].apply(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree to nderstand the decision paths and criteria at each node\n",
    "plt.figure(figsize=(20, 20))\n",
    "plot_tree(tree_model, filled=True, rounded=True, class_names=[\"Not OD\", \"OD\"], feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Feature Importances\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': tree_model.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance for Decision Tree')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree characteristics and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the decision paths for specific samples\n",
    "decision_paths = tree_model.decision_path(X_test)\n",
    "\n",
    "decision_paths_array = decision_paths.toarray()\n",
    "\n",
    "decision_paths_df = pd.DataFrame(decision_paths_array)\n",
    "decision_paths_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning to improve performance, and avoiding overfitting\n",
    "ccp_path = tree_model.cost_complexity_pruning_path(X_train, y_train)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ccp_path.ccp_alphas[:-1], ccp_path.impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
    "plt.xlabel(\"Effective Alpha\")\n",
    "plt.ylabel(\"Total Impurity of Leaves\")\n",
    "plt.title(\"Cost Complexity Pruning Path\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging the performance metrics\n",
    "y_pred = tree_model.predict(X_test)\n",
    "tree_metrics = calculate_metrics(y_test, y_pred, tree_model, X_test)\n",
    "\n",
    "wandb.log(tree_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging the tree characteristics\n",
    "tree_characteristics = calculate_tree_metrics(tree_model, X_test, y_test)\n",
    "\n",
    "wandb.log(tree_characteristics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "with open(\"models/tree_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tree_model, f)\n",
    "\n",
    "# Log the model as a versioned file\n",
    "artifact = wandb.Artifact(\"tree_model\", type=\"model\")\n",
    "artifact.add_file(\"models/tree_model.pkl\")\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "os.makedirs('data', exist_ok=True)\n",
    "datasets = {\"trainig\": X, \"validation\": y}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    df.to_csv(f'data/{name}.csv', index=False)\n",
    "\n",
    "# Log the `data` as an artifact\n",
    "artifact = wandb.Artifact('train_val_sets', type='dataset', metadata={\"Source\": \"CaseStudy_training_data.xlsx\"})\n",
    "artifact.add_dir('data')\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
