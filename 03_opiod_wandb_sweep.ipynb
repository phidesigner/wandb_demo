{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base on wandb documentation: Scikit-learn integration\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets, cluster\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import pickle\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, roc_curve, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed to detect the name of this notebook...\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = '03_opiod_wandb_sweep.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33midiazl\u001b[0m (\u001b[33mdev_ml_ops\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'CaseStudy_training_data.xlsx'\n",
    "df = pd.read_excel(data, sheet_name='Model_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "df_cleaned = df_cleaned.drop(['ID'], axis=1)\n",
    "df_cleaned = df_cleaned.rename(columns={'rx ds': 'rx_ds'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform percentile-based bucketing for 'rx_ds'\n",
    "df_features = df_cleaned.copy()\n",
    "df_features['rx_ds_bucket'] = pd.qcut(\n",
    "    df_cleaned['rx_ds'], \n",
    "    q=4, \n",
    "    labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature that is the sum of all the binary features\n",
    "binary_cols = [col for col in df_features.columns if col not in ['OD', 'rx_ds', 'rx_ds_bucket']]\n",
    "df_features['binary_sum'] = df_features[binary_cols].sum(axis=1)\n",
    "\n",
    "# Create a new feature that is the ratio of 'rx_ds' to the sum of binary features\n",
    "df_features['rx_ds_to_binary_sum'] = df_features['rx_ds'] / df_features['binary_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for 'rx_ds_bucket'\n",
    "df_one_hot = pd.get_dummies(df_features['rx_ds_bucket'], prefix='rx_ds_bucket')\n",
    "df_features = pd.concat([df_features, df_one_hot], axis=1)\n",
    "df_features.drop(['rx_ds_bucket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_log = df_features.copy()\n",
    "\n",
    "X = df_log.drop(['OD'], axis=1)\n",
    "y = df_log['OD']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to calculate the metrics for the classifier\n",
    "def calculate_metrics(y_test, y_pred, model, X_test):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "    metrics[\"precision\"] = precision_score(y_test, y_pred)\n",
    "    metrics[\"recall\"] = recall_score(y_test, y_pred)\n",
    "    metrics[\"f1\"] = f1_score(y_test, y_pred)\n",
    "    metrics[\"roc_auc\"] = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    \n",
    "    metrics[\"ppv\"] = TP / (TP + FP)\n",
    "    metrics[\"npv\"] = TN / (TN + FN)\n",
    "    metrics[\"specificity\"] = TN / (TN + FP)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New wandb project and run\n",
    "run = wandb.init(project='wandb-sklearn', name=\"classifier\")\n",
    "\n",
    "ridge_params = {\n",
    "    'penalty': 'l1',\n",
    "    'solver': 'liblinear',\n",
    "    'C': 0.1,\n",
    "    'class_weight': 'balanced',\n",
    "    'max_iter': 1000,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "wandb.config = ridge_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model, Fitting and predicting\n",
    "log_model = LogisticRegression(**ridge_params)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_logistic = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging the performance metrics\n",
    "y_pred = log_model.predict(X_test)\n",
    "log_metrics = calculate_metrics(y_test, y_pred, log_model, X_test)\n",
    "\n",
    "wandb.log(log_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact log_mode>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "with open(\"models/log_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(log_model, f)\n",
    "\n",
    "# Log the model as a versioned file\n",
    "artifact = wandb.Artifact(\"log_mode\", type=\"model\")\n",
    "artifact.add_file(\"models/log_model.pkl\")\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact train_val_sets>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the data\n",
    "os.makedirs('data', exist_ok=True)\n",
    "datasets = {\"trainig\": X, \"validation\": y}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    df.to_csv(f'data/{name}.csv', index=False)\n",
    "\n",
    "# Log the `data` as an artifact\n",
    "artifact = wandb.Artifact('train_val_sets', type='dataset', metadata={\"Source\": \"CaseStudy_training_data.xlsx\"})\n",
    "artifact.add_dir('data')\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>f1</td><td>▁</td></tr><tr><td>npv</td><td>▁</td></tr><tr><td>ppv</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr><tr><td>specificity</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.72</td></tr><tr><td>f1</td><td>0.64103</td></tr><tr><td>npv</td><td>0.91262</td></tr><tr><td>ppv</td><td>0.51546</td></tr><tr><td>precision</td><td>0.51546</td></tr><tr><td>recall</td><td>0.84746</td></tr><tr><td>roc_auc</td><td>0.81476</td></tr><tr><td>specificity</td><td>0.66667</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classifier</strong> at: <a href='https://wandb.ai/dev_ml_ops/wandb-sklearn/runs/8w4kp375' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sklearn/runs/8w4kp375</a><br/> View job at <a href='https://wandb.ai/dev_ml_ops/wandb-sklearn/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMDEwODM0Mg==/version_details/v1' target=\"_blank\">https://wandb.ai/dev_ml_ops/wandb-sklearn/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMDEwODM0Mg==/version_details/v1</a><br/>Synced 6 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231026_121236-8w4kp375/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
